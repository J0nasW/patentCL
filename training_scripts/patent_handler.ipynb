{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential Python libraries\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_patent_tsv = \"../data/g_patent.tsv\"\n",
    "g_us_citation_tsv = \"../data/g_us_patent_citation.tsv\"\n",
    "cpc_group_tsv = \"../data/cpc_group.tsv\"\n",
    "g_cpc_current_tsv = \"../data/g_cpc_current.tsv\"\n",
    "\n",
    "g_patent_csv = \"../data/g_patent.csv\"\n",
    "g_us_citation_csv = \"../data/g_us_patent_citation.csv\"\n",
    "cpc_group_csv = \"../data/cpc_group.csv\"\n",
    "g_cpc_current_csv = \"../data/g_cpc_current.csv\"\n",
    "\n",
    "triplet_training_csv = \"../data/triplet_training.csv\"\n",
    "\n",
    "## Neo4j database query:\n",
    "batch_size = 100000 # Define the size of each batch\n",
    "num_batches = 10 # Define the number of batches to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the g patents tsv in to a pandas dataframe with chunks. Use tqdm to track progress in the jupyter notebook\n",
    "\n",
    "g_patents_df = pd.DataFrame()\n",
    "print('Loading the g_patent.tsv file...')\n",
    "for chunk in tqdm(pd.read_csv(g_patent_tsv, sep='\\t', chunksize=1000000, low_memory=False), total=9):\n",
    "    g_patents_df = pd.concat([g_patents_df, chunk])\n",
    "\n",
    "# rename the columns to match the neo4j import database schema\n",
    "g_patents_df.rename(columns={'patent_id': 'patentId:ID', \"patent_title\": \"title:str\", \"patent_abstract\":\"abstract:str\", \"num_claims\": \"num_claims:int\", \"patent_type\":\"patent_type:str\", \"patent_date\": \"date:neo4j.time.Date\", \"filename\": \"filename:str\"}, inplace=True)\n",
    "\n",
    "# Add a column \":LABEL\" and fill it with the string \"Patent\"\n",
    "g_patents_df[':LABEL'] = 'Patent'\n",
    "\n",
    "# Add a column \"import_date:neo4j.time.DateTime\" and fill it with the current date and time\n",
    "g_patents_df['import_date:neo4j.time.DateTime'] = pd.to_datetime('now')\n",
    "\n",
    "# drop the columns that are not needed\n",
    "g_patents_df.drop(columns=['withdrawn'], inplace=True)\n",
    "\n",
    "print(g_patents_df.head(5))\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "print('Saving the g_patent.csv file...')\n",
    "g_patents_df.to_csv(g_patent_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the g citations tsv in to a pandas dataframe with chunks. Use tqdm to track progress in the jupyter notebook\n",
    "\n",
    "g_citation_df = pd.DataFrame()\n",
    "print('Loading the g_us_patent_citation.tsv file...')\n",
    "for chunk in tqdm(pd.read_csv(g_us_citation_tsv, sep='\\t', chunksize=1000000, low_memory=False), total=129):\n",
    "    g_citation_df = pd.concat([g_citation_df, chunk])\n",
    "\n",
    "# rename the columns to match the neo4j import database schema\n",
    "g_citation_df.rename(columns={'patent_id': ':START_ID', \"citation_patent_id\": \":END_ID\", \"citation_sequence\":\"citation_sequence:str\", \"citation_date\": \"date:neo4j.time.Date\", \"record_name\": \"record_name:str\"}, inplace=True)\n",
    "\n",
    "# Add a column \":LABEL\" and fill it with the string \"Patent\"\n",
    "g_citation_df[':TYPE'] = 'cites'\n",
    "\n",
    "# Add a column \"import_date:neo4j.time.DateTime\" and fill it with the current date and time\n",
    "g_citation_df['import_date:neo4j.time.DateTime'] = pd.to_datetime('now')\n",
    "\n",
    "# drop the columns that are not needed\n",
    "g_citation_df.drop(columns=[\"wipo_kind\", \"citation_category\"], inplace=True)\n",
    "\n",
    "print(g_patents_df.head(5))\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "print('Saving the g_citation.csv file...')\n",
    "g_citation_df.to_csv(g_us_citation_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the cpc_group.csv file...\n"
     ]
    }
   ],
   "source": [
    "cpc_groups = pd.read_csv(cpc_group_tsv, sep='\\t', low_memory=False)\n",
    "\n",
    "# rename the columns to match the neo4j import database schema\n",
    "cpc_groups.rename(columns={\n",
    "    'id': 'cpcId:ID',\n",
    "    \"title\": \"title\"\n",
    "    }, inplace=True)\n",
    "\n",
    "# Add a column \":LABEL\" and fill it with the string \"CPCGroup\"\n",
    "cpc_groups[':LABEL'] = 'CPCGroup'\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "print('Saving the cpc_group.csv file...')\n",
    "cpc_groups.to_csv(cpc_group_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the g_cpc_current.tsv file...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4e912c51df40c89d11eb1def1a450d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    :END_ID  cpc_sequence cpc_section cpc_class :START_ID      cpc_group  \\\n",
      "0   4796895             1           F       F16      F16H      F16H61/00   \n",
      "1  10913199             0           B       B29      B29C      B29C55/08   \n",
      "2   5208443             0           B       B29      B29C     B29C65/366   \n",
      "3   7830588             6           G       G09      G09G  G09G2310/0275   \n",
      "4   7232943             1           A       A01      A01H       A01H5/10   \n",
      "\n",
      "      cpc_type       :TYPE                import_date  \n",
      "0  inventional  classifies 2023-06-21 14:37:29.759365  \n",
      "1  inventional  classifies 2023-06-21 14:37:29.759365  \n",
      "2  inventional  classifies 2023-06-21 14:37:29.759365  \n",
      "3   additional  classifies 2023-06-21 14:37:29.759365  \n",
      "4  inventional  classifies 2023-06-21 14:37:29.759365  \n",
      "Saving the g_cpc.csv file...\n"
     ]
    }
   ],
   "source": [
    "g_cpc = pd.DataFrame()\n",
    "print('Loading the g_cpc_current.tsv file...')\n",
    "for chunk in tqdm(pd.read_csv(g_cpc_current_tsv, sep='\\t', chunksize=1000000, low_memory=False), total=49):\n",
    "    g_cpc = pd.concat([g_cpc, chunk])\n",
    "\n",
    "# rename the columns to match the neo4j import database schema\n",
    "g_cpc.rename(columns={\n",
    "    'patent_id': ':END_ID',\n",
    "    \"cpc_subclass\": \":START_ID\",\n",
    "}, inplace=True)\n",
    "\n",
    "# Add a column \":LABEL\" and fill it with the string \"CPCGroup\"\n",
    "g_cpc[':TYPE'] = 'classifies'\n",
    "\n",
    "# Add a column \"import_date:neo4j.time.DateTime\" and fill it with the current date and time\n",
    "g_cpc['import_date'] = pd.to_datetime('now')\n",
    "\n",
    "# drop the columns that are not needed\n",
    "g_cpc.drop(columns=[\"cpc_symbol_position\"], inplace=True)\n",
    "\n",
    "print(g_cpc.head(5))\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "print('Saving the g_cpc.csv file...')\n",
    "g_cpc.to_csv(g_cpc_current_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herader changer\n",
    "\n",
    "import fileinput\n",
    "\n",
    "# Modify the header row in the CSV file\n",
    "for line in fileinput.input('g_patent.csv', inplace=True):\n",
    "    if fileinput.isfirstline():\n",
    "        # line = line.replace('title:str', 'title')\n",
    "        # line = line.replace('abstract:str', 'abstract')\n",
    "        # line = line.replace('patent_type:str', 'patent_type')\n",
    "        # line = line.replace('filename:str', 'filename')\n",
    "        line = line.replace('date:neo4j.time.Date', 'date')\n",
    "        line = line.replace('import_date:neo4j.time.Date', 'import_date')\n",
    "    print(line, end='')\n",
    "\n",
    "for line in fileinput.input(\"g_citation.csv\", inplace=True):\n",
    "    if fileinput.isfirstline():\n",
    "        # line = line.replace('citation_sequence:str', 'citation_sequence')\n",
    "        # line = line.replace('record_name:str', 'record_name')\n",
    "        line = line.replace('date:neo4j.time.Date', 'date')\n",
    "        line = line.replace('import_date:neo4j.time.Date', 'import_date')\n",
    "    print(line, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To import the csv Files into neo4j, use the import admin tool: https://neo4j.com/docs/operations-manual/current/tutorial/neo4j-admin-import/\n",
    "\n",
    "Possible and working import command:\n",
    "<!-- ```\n",
    "bin/neo4j-admin database import full --nodes=import/g_patent.csv --relationships=import/g_citation.csv --multiline-fields=true --skip-bad-relationships --bad-tolerance=100000000 --skip-duplicate-nodes patentsview\n",
    "``` -->\n",
    "\n",
    "```\n",
    "bin/neo4j-admin database import full --nodes=import/g_patent.csv --nodes=import/cpc_group.csv --relationships=import/g_citation.csv --relationships=import/g_cpc.csv --multiline-fields --skip-bad-relationships --bad-tolerance=100000000 --skip-duplicate-nodes patentsviewcpc\n",
    "```\n",
    "\n",
    "Adhere to the following steps:\n",
    "1. Stop the server\n",
    "2. Run the admin -import tool and use a new database name (e.g. patentsview). You can also choose an existing one but with the flag --overwrite-destination.\n",
    "3. Start the server\n",
    "4. In the console switch to the System database using the pulldown control\n",
    "5. Run the following command at the system prompt: create database aDatabaseName (should be the same name set in #2 above)\n",
    "6. Switch to the database just created using the console pulldown control\n",
    "\n",
    "When the import is finished, return here to generate the contrastive learning triplets from neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 8217 rows from the database for batch 1\n",
      "Fetched 8278 rows from the database for batch 2\n",
      "Fetched 8264 rows from the database for batch 3\n",
      "Fetched 8316 rows from the database for batch 4\n",
      "Fetched 8089 rows from the database for batch 5\n",
      "Fetched 8269 rows from the database for batch 6\n",
      "Fetched 8261 rows from the database for batch 7\n",
      "Fetched 8126 rows from the database for batch 8\n",
      "Fetched 8181 rows from the database for batch 9\n",
      "Fetched 8324 rows from the database for batch 10\n",
      "Concatenated 82325 rows from all batches\n",
      "Reduced the dataframe to 82325 rows after removing duplicates\n"
     ]
    }
   ],
   "source": [
    "import neo4j\n",
    "\n",
    "# Connect to the neo4j database\n",
    "driver = neo4j.GraphDatabase.driver(\"bolt://localhost:7687\", auth=(\"neo4j\", \"your_password\"))\n",
    "session = driver.session(database=\"patentsview\")\n",
    "\n",
    "# Define an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Execute the query in batches\n",
    "for i in range(num_batches):\n",
    "    # Define the start and end indices for the batch\n",
    "    start_index = i * batch_size\n",
    "    end_index = (i + 1) * batch_size\n",
    "    \n",
    "    # Define the query for the batch\n",
    "    query = f\"\"\"\n",
    "        CALL {{\n",
    "            MATCH (anchor:Patent)\n",
    "            WITH DISTINCT anchor SKIP {start_index} LIMIT {batch_size}\n",
    "            RETURN DISTINCT anchor\n",
    "        }}\n",
    "        CALL {{\n",
    "            WITH anchor\n",
    "            MATCH (anchor)-[:cites]->(cited:Patent)<-[:classifies]-(cpc:CPCGroup)-[:classifies]->(anchor)\n",
    "            WHERE anchor <> cited\n",
    "            WITH DISTINCT cited, cpc LIMIT 1\n",
    "            RETURN DISTINCT cited, cpc\n",
    "        }}\n",
    "        CALL {{\n",
    "            WITH anchor, cited, cpc\n",
    "            MATCH (other:Patent)\n",
    "            WHERE NOT EXISTS {{\n",
    "                MATCH (anchor)-[:cites]->(other:Patent)<-[:classifies]-(cpc)-[:classifies]->(anchor)\n",
    "                WHERE anchor <> other\n",
    "            }}\n",
    "            WITH DISTINCT other LIMIT 1\n",
    "            RETURN DISTINCT other\n",
    "        }}\n",
    "        RETURN anchor.patentId AS a_id, anchor.title AS a_title, anchor.abstract AS a_abstract, cited.patentId AS p_id, cited.title AS p_title, cited.abstract AS p_abstract, other.patentId AS n_id, other.title AS n_title, other.abstract AS n_abstract, cpc.cpcId AS cpc_id\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query and append the results to the list\n",
    "    df = pd.DataFrame(session.run(query).data())\n",
    "    results.append(df)\n",
    "\n",
    "    print(f\"Fetched {len(df)} rows from the database for batch {i+1}\")\n",
    "\n",
    "# Concatenate the results into a single dataframe\n",
    "df = pd.concat(results)\n",
    "\n",
    "print(f\"Concatenated {len(df)} rows from all batches\")\n",
    "\n",
    "# Reduce the dataframe to remove duplicates in the a_id column\n",
    "df = df.drop_duplicates(subset=['a_id'])\n",
    "\n",
    "print(f\"Reduced the dataframe to {len(df)} rows after removing duplicates\")\n",
    "\n",
    "# Save the df to a csv file\n",
    "print('Saving the df to csv...')\n",
    "df.to_csv(triplet_training_csv, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
